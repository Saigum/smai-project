{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a0ce224-de73-4c72-9488-3f449fd9bbd2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-03T10:48:46.409913Z",
     "iopub.status.idle": "2025-05-03T10:48:46.410132Z",
     "shell.execute_reply": "2025-05-03T10:48:46.410038Z",
     "shell.execute_reply.started": "2025-05-03T10:48:46.410028Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11x-cls.pt to 'yolo11x-cls.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56.9M/56.9M [00:24<00:00, 2.46MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.124 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.123 🚀 Python-3.13.1 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11012MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolo11x-cls.pt, data=./dataset, epochs=50, time=None, patience=100, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=yolo11x-cls, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=0.0, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, cutmix=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/yolo11x-cls\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /scratch/saigum/smai/dataset/train... found 6540 images in 181 classes ✅ \n",
      "ERROR ❌ \u001b[34m\u001b[1mval:\u001b[0m /scratch/saigum/smai/dataset/val... found 369 images in 146 classes (requires 181 classes, not 146)\n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "Overriding model.yaml nc=80 with nc=181\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2784  ultralytics.nn.modules.conv.Conv             [3, 96, 3, 2]                 \n",
      "  1                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  2                  -1  2    389760  ultralytics.nn.modules.block.C3k2            [192, 384, 2, True, 0.25]     \n",
      "  3                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      "  4                  -1  2   1553664  ultralytics.nn.modules.block.C3k2            [384, 768, 2, True, 0.25]     \n",
      "  5                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      "  6                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
      "  7                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      "  8                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
      "  9                  -1  2   3264768  ultralytics.nn.modules.block.C2PSA           [768, 768, 2]                 \n",
      " 10                  -1  1   1217461  ultralytics.nn.modules.head.Classify         [768, 181]                    \n",
      "YOLO11x-cls summary: 176 layers, 28,587,925 parameters, 28,587,925 gradients, 111.2 GFLOPs\n",
      "Transferred 492/494 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2099.1±486.1 MB/s, size: 92.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /scratch/saigum/smai/dataset/train... 6540 images, 0 corrupt: 100%|██████████| 6540/6540 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/0/img_5750.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/0/img_5754.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/0/img_5759.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/0/img_5760.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/0/img_5761.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/0/img_5763.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/0/img_5764.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/0/img_5769.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/0/img_5774.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/0/img_5778.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/0/img_5781.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/0/img_5783.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/0/img_5788.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/0/img_5789.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/180/img_5744.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/180/img_5751.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/180/img_5752.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/180/img_5756.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/180/img_5758.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/180/img_5766.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/180/img_5770.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/180/img_5771.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/180/img_5772.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/180/img_5773.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/180/img_5784.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/180/img_5785.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/90/img_5741.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/90/img_5742.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/90/img_5743.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/90/img_5745.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/90/img_5746.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/90/img_5747.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/90/img_5748.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/90/img_5749.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/90/img_5753.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/90/img_5755.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/90/img_5757.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/90/img_5762.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/90/img_5765.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/90/img_5767.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/90/img_5768.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/90/img_5775.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/90/img_5776.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/90/img_5777.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/90/img_5779.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/90/img_5780.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/90/img_5782.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/90/img_5786.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/scratch/saigum/smai/dataset/train/90/img_5787.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 995.2±386.6 MB/s, size: 48.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /scratch/saigum/smai/dataset/val... 369 images, 0 corrupt: 100%|██████████| 369/369 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0m/scratch/saigum/smai/dataset/val/90/img_0324.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/scratch/saigum/smai/dataset/val/90/img_0325.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/scratch/saigum/smai/dataset/val/90/img_0326.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=5.4e-05, momentum=0.9) with parameter groups 82 weight(decay=0.0), 83 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/classify/yolo11x-cls\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50      1.91G      5.272         12        224: 100%|██████████| 409/409 [00:42<00:00,  9.67it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 27.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          0     0.0163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50      1.96G      5.169         12        224: 100%|██████████| 409/409 [00:37<00:00, 10.93it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 35.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          0     0.0163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50      1.96G      5.085         12        224: 100%|██████████| 409/409 [00:36<00:00, 11.16it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 37.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00271     0.0379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50      2.12G      5.012         12        224: 100%|██████████| 409/409 [00:35<00:00, 11.51it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 35.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          0     0.0352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50      2.13G      4.927         12        224: 100%|██████████| 409/409 [00:34<00:00, 11.96it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 37.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          0     0.0434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50      2.13G      4.826         12        224: 100%|██████████| 409/409 [00:36<00:00, 11.13it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 32.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00542     0.0379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50      2.13G      4.727         12        224: 100%|██████████| 409/409 [00:37<00:00, 10.91it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 36.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00271     0.0461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50      2.17G      4.624         12        224: 100%|██████████| 409/409 [00:34<00:00, 11.81it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 34.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00271     0.0434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50       2.2G       4.52         12        224: 100%|██████████| 409/409 [00:36<00:00, 11.18it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 35.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00542     0.0379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50      2.21G      4.408         12        224: 100%|██████████| 409/409 [00:36<00:00, 11.08it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 37.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00271     0.0434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50      2.21G        4.3         12        224: 100%|██████████| 409/409 [00:34<00:00, 11.83it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 37.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00271     0.0461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50      2.21G      4.212         12        224: 100%|██████████| 409/409 [00:34<00:00, 11.99it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 36.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00542     0.0434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50      2.21G      4.125         12        224: 100%|██████████| 409/409 [00:33<00:00, 12.30it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 36.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00271     0.0434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50      2.24G      4.029         12        224: 100%|██████████| 409/409 [00:35<00:00, 11.62it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 31.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00813     0.0488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50      2.39G      3.937         12        224: 100%|██████████| 409/409 [00:35<00:00, 11.57it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 35.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0108     0.0407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50       2.5G      3.844         12        224: 100%|██████████| 409/409 [00:34<00:00, 11.73it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 35.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00813     0.0352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50       2.5G      3.755         12        224: 100%|██████████| 409/409 [00:33<00:00, 12.16it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 37.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00542     0.0352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50       2.5G      3.651         12        224: 100%|██████████| 409/409 [00:36<00:00, 11.11it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 35.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00542     0.0461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50       2.5G      3.575         12        224: 100%|██████████| 409/409 [00:35<00:00, 11.48it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 35.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00813     0.0434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50      2.55G      3.508         12        224: 100%|██████████| 409/409 [00:35<00:00, 11.68it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 34.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00542     0.0325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      2.65G      3.407         12        224: 100%|██████████| 409/409 [00:36<00:00, 11.09it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 34.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0108     0.0379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50      2.65G      3.333         12        224: 100%|██████████| 409/409 [00:36<00:00, 11.13it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 35.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00542     0.0298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50      2.65G      3.257         12        224: 100%|██████████| 409/409 [00:34<00:00, 11.79it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 37.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00542     0.0244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50      2.65G      3.176         12        224: 100%|██████████| 409/409 [00:36<00:00, 11.23it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 37.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00542     0.0298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50      2.65G      3.106         12        224: 100%|██████████| 409/409 [00:35<00:00, 11.46it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 36.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00813     0.0352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50      2.69G      3.025         12        224: 100%|██████████| 409/409 [00:35<00:00, 11.54it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 36.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00542     0.0352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50      2.71G      2.967         12        224: 100%|██████████| 409/409 [00:34<00:00, 11.71it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 36.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00542     0.0298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      2.82G      2.888         12        224: 100%|██████████| 409/409 [00:33<00:00, 12.10it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 35.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00813     0.0325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50      2.82G      2.835         12        224: 100%|██████████| 409/409 [00:33<00:00, 12.20it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 37.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00813     0.0217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50      2.82G      2.773         12        224: 100%|██████████| 409/409 [00:36<00:00, 11.08it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 36.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00813     0.0271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50      2.82G      2.717         12        224: 100%|██████████| 409/409 [00:34<00:00, 11.94it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 36.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00542     0.0271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50      2.82G      2.668         12        224: 100%|██████████| 409/409 [00:35<00:00, 11.67it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 36.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00542     0.0271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50      2.82G      2.597         12        224: 100%|██████████| 409/409 [00:36<00:00, 11.11it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 37.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00542     0.0244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50      2.82G      2.556         12        224: 100%|██████████| 409/409 [00:35<00:00, 11.66it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 36.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00813     0.0271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50      2.82G      2.496         12        224: 100%|██████████| 409/409 [00:35<00:00, 11.48it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 36.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00542     0.0217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50      2.82G      2.466         12        224: 100%|██████████| 409/409 [00:35<00:00, 11.44it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 36.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00271     0.0271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50      2.82G      2.418         12        224: 100%|██████████| 409/409 [00:35<00:00, 11.55it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 36.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00542      0.019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50      2.82G      2.369         12        224: 100%|██████████| 409/409 [00:35<00:00, 11.63it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 37.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00542     0.0244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50      2.82G      2.334         12        224: 100%|██████████| 409/409 [00:34<00:00, 11.89it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 37.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00271     0.0271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50      2.82G       2.28         12        224: 100%|██████████| 409/409 [00:35<00:00, 11.53it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 36.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00813     0.0217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50      2.82G      2.263         12        224: 100%|██████████| 409/409 [00:36<00:00, 11.25it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 36.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00542     0.0244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50      2.82G      2.233         12        224: 100%|██████████| 409/409 [00:36<00:00, 11.34it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 35.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00542     0.0217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50      2.82G      2.207         12        224: 100%|██████████| 409/409 [00:35<00:00, 11.60it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 37.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00542     0.0271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50      2.82G      2.179         12        224: 100%|██████████| 409/409 [00:35<00:00, 11.37it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 35.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00271     0.0271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50      2.82G       2.13         12        224: 100%|██████████| 409/409 [00:37<00:00, 10.94it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 31.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00271     0.0244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50      2.82G      2.124         12        224: 100%|██████████| 409/409 [00:36<00:00, 11.23it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 36.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00271     0.0271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50      2.82G      2.101         12        224: 100%|██████████| 409/409 [00:35<00:00, 11.38it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 37.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00271     0.0244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50      2.82G      2.095         12        224: 100%|██████████| 409/409 [00:37<00:00, 11.00it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 35.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00271     0.0244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50      2.82G      2.082         12        224: 100%|██████████| 409/409 [00:34<00:00, 11.74it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 37.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00271     0.0217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50      2.82G      2.072         12        224: 100%|██████████| 409/409 [00:37<00:00, 11.03it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 33.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00271     0.0217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50 epochs completed in 0.516 hours.\n",
      "Optimizer stripped from runs/classify/yolo11x-cls/weights/last.pt, 57.5MB\n",
      "Optimizer stripped from runs/classify/yolo11x-cls/weights/best.pt, 57.5MB\n",
      "\n",
      "Validating runs/classify/yolo11x-cls/weights/best.pt...\n",
      "Ultralytics 8.3.123 🚀 Python-3.13.1 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11012MiB)\n",
      "YOLO11x-cls summary (fused): 94 layers, 28,564,277 parameters, 0 gradients, 110.5 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /scratch/saigum/smai/dataset/train... found 6540 images in 181 classes ✅ \n",
      "ERROR ❌ \u001b[34m\u001b[1mval:\u001b[0m /scratch/saigum/smai/dataset/val... found 369 images in 146 classes (requires 181 classes, not 146)\n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:00<00:00, 28.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00813     0.0488\n",
      "Speed: 0.1ms preprocess, 1.0ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/classify/yolo11x-cls\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7f2700268de0>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.028455283492803574\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.008130080997943878, 'metrics/accuracy_top5': 0.04878048598766327, 'fitness': 0.028455283492803574}\n",
       "save_dir: PosixPath('runs/classify/yolo11x-cls')\n",
       "speed: {'preprocess': 0.06176743089335546, 'inference': 0.9653933143663701, 'loss': 0.00035182927057006945, 'postprocess': 0.0007122249361745973}\n",
       "task: 'classify'\n",
       "top1: 0.008130080997943878\n",
       "top5: 0.04878048598766327"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolo11x-cls.pt')\n",
    "\n",
    "# Train on dataset/, no internal split:\n",
    "model.train(\n",
    "    data='./dataset',        # <-- THIS is the parent with train/ & val/\n",
    "    task='classify',\n",
    "    epochs=50,\n",
    "    batch=16,\n",
    "    split=0.0,               # disable any additional split\n",
    "    name='yolo11x-cls',       # save to runs/classify/train/exp\n",
    "    device=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b516917b-a3ee-49d5-a4e4-596ec931a3af",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to \u001b[1mruns/classify/predict2\u001b[0m\n",
      "369 labels saved to runs/classify/predict2/labels\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"/scratch/saigum/smai/runs/classify/yolo11x-cls/weights/best.pt\")\n",
    "results = model.predict(\n",
    "    source='./images_val/images_val',  # your separate val folder\n",
    "    task='classify',\n",
    "    batch=16,\n",
    "    verbose=False,\n",
    "    save_txt=True,\n",
    "    save=False    # if you want to save output images with labels\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bfd06f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3813/1113762563.py:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  pred = sub.groupby('filename').apply(lambda g: np.average(g['angle'], weights=g['probability'])).rename('pred_angle').reset_index()\n",
      "/tmp/ipykernel_3813/1113762563.py:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  pred = sub.groupby('filename').apply(lambda g: np.average(g['angle'], weights=g['probability'])).rename('pred_angle').reset_index()\n",
      "/tmp/ipykernel_3813/1113762563.py:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  pred = sub.groupby('filename').apply(lambda g: np.average(g['angle'], weights=g['probability'])).rename('pred_angle').reset_index()\n",
      "/tmp/ipykernel_3813/1113762563.py:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  pred = sub.groupby('filename').apply(lambda g: np.average(g['angle'], weights=g['probability'])).rename('pred_angle').reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1 weighted MAE: 43.8130\n",
      "Rank 2 weighted MAE: 41.0674\n",
      "Rank 3 weighted MAE: 40.7838\n",
      "Rank 4 weighted MAE: 40.7467\n",
      "Rank 5 weighted MAE: 40.1215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3813/1113762563.py:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  pred = sub.groupby('filename').apply(lambda g: np.average(g['angle'], weights=g['probability'])).rename('pred_angle').reset_index()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trues = pd.read_csv('labels_val.csv', usecols=['angle','filename'])\n",
    "trues['true_angle'] = trues.pop('angle')\n",
    "trues['filename'] = trues['filename'].str.replace(r'\\.\\w+$','',regex=True)\n",
    "\n",
    "records = []\n",
    "for fp in glob.glob('/scratch/saigum/smai/runs/classify/yolo11x-cls2/labels/*.txt'):\n",
    "    fn = os.path.basename(fp).replace('.txt','')\n",
    "    with open(fp) as f:\n",
    "        for rank,line in enumerate(f,1):\n",
    "            p,c = line.split()\n",
    "            records.append({'filename':fn,'rank':rank,'angle':int(c),'probability':float(p)})\n",
    "\n",
    "df = pd.DataFrame(records).merge(trues, on='filename')\n",
    "\n",
    "def wrap(a): return min(a,360-a)\n",
    "results = {}\n",
    "for k in [1,2,3,4,5]:\n",
    "    sub = df[df['rank']<=k]\n",
    "    pred = sub.groupby('filename').apply(lambda g: np.average(g['angle'], weights=g['probability'])).rename('pred_angle').reset_index()\n",
    "    m = pred.merge(trues, on='filename')\n",
    "    m = m[m['true_angle']<=360].copy()\n",
    "    m['wt_true'] = m['true_angle'].apply(wrap)\n",
    "    m['wt_pred'] = m['pred_angle'].apply(wrap)\n",
    "    results[k] = (m['wt_pred'] - m['wt_true']).abs().mean()\n",
    "\n",
    "for k,mae in results.items():\n",
    "    print(f\"Rank{str(k).rjust(2)} weighted MAE: {mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9fa68a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'true_angle'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/saigum/smai/yl/lib/python3.13/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'true_angle'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m top1 = df[df[\u001b[33m'\u001b[39m\u001b[33mrank\u001b[39m\u001b[33m'\u001b[39m]==\u001b[32m1\u001b[39m].merge(trues, on=\u001b[33m'\u001b[39m\u001b[33mfilename\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m f = top1[\u001b[43mtop1\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrue_angle\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m<=\u001b[32m360\u001b[39m].copy()\n\u001b[32m      3\u001b[39m f[\u001b[33m'\u001b[39m\u001b[33mwt_true\u001b[39m\u001b[33m'\u001b[39m] = f[\u001b[33m'\u001b[39m\u001b[33mtrue_angle\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m a: \u001b[38;5;28mmin\u001b[39m(a,\u001b[32m360\u001b[39m-a))\n\u001b[32m      4\u001b[39m f[\u001b[33m'\u001b[39m\u001b[33mwt_pred\u001b[39m\u001b[33m'\u001b[39m] = f[\u001b[33m'\u001b[39m\u001b[33mangle\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m a: \u001b[38;5;28mmin\u001b[39m(a,\u001b[32m360\u001b[39m-a))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/saigum/smai/yl/lib/python3.13/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/saigum/smai/yl/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'true_angle'"
     ]
    }
   ],
   "source": [
    "\n",
    "top1 = df[df['rank']==1].merge(trues, on='filename')\n",
    "f = top1[top1['true_angle']<=360].copy()\n",
    "f['wt_true'] = f['true_angle'].apply(lambda a: min(a,360-a))\n",
    "f['wt_pred'] = f['angle'].apply(lambda a: min(a,360-a))\n",
    "maae = (f['wt_pred'] - f['wt_true']).abs().mean()\n",
    "print(f\"Mean Absolute Angular Error: {maae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b687d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "top1=df[df['rank']==1].merge(trues,on='filename')\n",
    "f=top1[top1['true_angle']<=360].copy()\n",
    "f['wt_true']=f['true_angle'].apply(lambda a: min(a,360-a))\n",
    "f['wt_pred']=f['angle'].apply(lambda a: min(a,360-a))\n",
    "maae=(f['wt_pred']-f['wt_true']).abs().mean()\n",
    "print(f\"Mean Absolute Angular Error: {maae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a9d003-937d-49aa-a127-dc9af7ce4713",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7317338,
     "sourceId": 11660102,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "yl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 49.860487,
   "end_time": "2025-05-01T13:40:55.596174",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-01T13:40:05.735687",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
